{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline  \n",
    "\n",
    "import pandas as pd\n",
    "import consolidateFiles as cf\n",
    "import datacleaning as cl\n",
    "import fragmentation as fr\n",
    "import hervpd as hp\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ! Parse activity files and parse interval files are to be replaced with the corresponding database queries as soon as they are available "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 - Pipeline configuration \n",
    "* set the input/output directories, user id and verbose level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = True\n",
    "\n",
    "PATH = \"C:\\\\Users\\\\ju\\\\GDrive\\\\Projects\\\\HeRV\\\\Data\\\\\"\n",
    "RAW_PATH = PATH + \"Raw\"\n",
    "PRE_PATH = PATH + \"PreProcessed\"\n",
    "\n",
    "sessfile = PRE_PATH + \"\\\\sessions.xlsx\"  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Read sessions\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(sessfile)\n",
    "df.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = df.to_dict(orient='records')\n",
    "%time sessions = cf.sessions_add_beats(sessions, RAW_PATH, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2 - Generate fragments from sessions\n",
    "\n",
    "Breaks the sessions duration in fragments\n",
    "\n",
    "Configurations:\n",
    "* duration of each fragment in seconds;\n",
    "* number of seconds to be discarded at the beginning of the session, accounting for user's stabilization and adjustment to posture and activity \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# duration (in seconds) to be cropped from the beginning of each second to account for stabilization and user adjustment\n",
    "crop = 0\n",
    "    \n",
    "# duration (in seconds) of each fragment to be sent to analysis\n",
    "duration = 60\n",
    "    \n",
    "# if any fragment has more than 'threshold' consecutive seconds with no beats, it will be discarded\n",
    "threshold = 3    \n",
    "\n",
    "%time frags = fr.gen_fragments_dataset(sessions, duration, crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# [(s['activity'], s['start'], s['stop']) for s in sessions if s['start'] > datetime(2017,10,14,11) and s['stop'] < datetime(2017,10,14,23) and s['user'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Save\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(frags)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df[(df.user == 2 ) & (df.start > datetime(2017,10,26,20,40)) & (df.start < datetime(2017,10,26,20,59))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = PRE_PATH + '\\\\df_' + str(duration) + '_' + str(crop) + '.xlsx'\n",
    "print(filename)\n",
    "df.to_excel(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying all steps above to generate different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# durations = [300, 240, 180, 150, 120, 90, 60]\n",
    "# crops = [120, 90, 60]\n",
    "\n",
    "# durations = [20, 30, 60, 90, 120, 150, 180]\n",
    "# crops = [10, 30]\n",
    "\n",
    "durations = [30, 300]\n",
    "crops= [30]\n",
    "\n",
    "def multifrag(sessions, durations, crops, path_out):\n",
    "    for cr in crops:\n",
    "        for dr in durations:            \n",
    "            print ('generating dataset for duration', dr, 'and crop', cr, '...')\n",
    "            ds = fr.gen_fragments_dataset(sessions, dr, cr)\n",
    "            print('resulting dataset:', len(ds), 'records' )\n",
    "            fname = path_out + '\\\\df_' + str(dr) + '_' + str(cr) + '.xlsx'            \n",
    "            ds.to_excel(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%time multifrag(sessions, durations, crops, PRE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ( Extra - save files for LDA Grover)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr[['activity']].to_csv('./classifications')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ints(beats):\n",
    "    return [beat['interval'] for beat in beats]\n",
    "\n",
    "dfr['ts'] = dfr['rr'].apply(get_ints)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr.loc[['ts']].sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr[['ts']].to_csv('./timeseries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr[cl.features_all].to_csv('./features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in d.activity.unique()\n",
    "       df.groupby(column).count()['user']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
